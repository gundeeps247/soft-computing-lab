{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in X: 0 Inf in X: 0\n",
      "NaN in Crisp y: 0 Inf in Crisp y: 0\n",
      "NaN in Fuzzy y: 0 Inf in Fuzzy y: 0\n",
      "\n",
      "Training for Crisp Logic:\n",
      "Epoch 0 (Crisp Logic) Error: 0.4948521921285138\n",
      "Epoch 1000 (Crisp Logic) Error: 0.4977641990335058\n",
      "Epoch 2000 (Crisp Logic) Error: 0.497481014749353\n",
      "Epoch 3000 (Crisp Logic) Error: 0.4963728554215307\n",
      "Epoch 4000 (Crisp Logic) Error: 0.49585352831516966\n",
      "Epoch 5000 (Crisp Logic) Error: 0.49435092922982043\n",
      "Epoch 6000 (Crisp Logic) Error: 0.49534495654622435\n",
      "Epoch 7000 (Crisp Logic) Error: 0.4952056315476408\n",
      "Epoch 8000 (Crisp Logic) Error: 0.4965312813862395\n",
      "Epoch 9000 (Crisp Logic) Error: 0.49649141758087695\n",
      "\n",
      "Training for Fuzzy Logic:\n",
      "Epoch 0 (Fuzzy Logic) Error: 0.13833725902277588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gunde\\AppData\\Local\\Temp\\ipykernel_29204\\4042997811.py:44: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 (Fuzzy Logic) Error: 0.13296844788482692\n",
      "Epoch 2000 (Fuzzy Logic) Error: 0.1329485797752414\n",
      "Epoch 3000 (Fuzzy Logic) Error: 0.13293099386698856\n",
      "Epoch 4000 (Fuzzy Logic) Error: 0.1329152885917221\n",
      "Epoch 5000 (Fuzzy Logic) Error: 0.1329011545953307\n",
      "Epoch 6000 (Fuzzy Logic) Error: 0.1328883490934512\n",
      "Epoch 7000 (Fuzzy Logic) Error: 0.13287667851412818\n",
      "Epoch 8000 (Fuzzy Logic) Error: 0.13286598639115552\n",
      "Epoch 9000 (Fuzzy Logic) Error: 0.13285614471412174\n",
      "\n",
      "Crisp Logic Accuracy: 51.181102362204726%\n",
      "Fuzzy Logic Accuracy: 42.125984251968504%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('asiacup.csv')\n",
    "\n",
    "# Preprocessing\n",
    "data['Result'] = data['Result'].apply(lambda x: 1 if x.lower() == 'win' else 0)\n",
    "\n",
    "# Crisp Logic: Use binary win/lose result directly\n",
    "crisp_y = data['Result'].values.reshape(-1, 1)\n",
    "\n",
    "# Fuzzy Logic: Introduce a fuzzy version based on heuristics\n",
    "# Here, a simple heuristic could be that the more runs and fewer wickets lost, the higher the fuzzy result.\n",
    "data['Fuzzy Result'] = (data['Run Scored'] / data['Run Scored'].max()) * 0.6 + (1 - data['Wicket Lost'] / data['Wicket Lost'].max()) * 0.4\n",
    "fuzzy_y = data['Fuzzy Result'].values.reshape(-1, 1)\n",
    "\n",
    "# Features (Run Scored, Wicket Lost, Fours, Sixes, Extras)\n",
    "X = data[['Run Scored', 'Wicket Lost', 'Fours', 'Sixes', 'Extras']].values\n",
    "\n",
    "# Handling missing values (NaN)\n",
    "X = np.nan_to_num(X)\n",
    "crisp_y = np.nan_to_num(crisp_y)\n",
    "fuzzy_y = np.nan_to_num(fuzzy_y)\n",
    "\n",
    "# Check for NaN and Inf values\n",
    "print(\"NaN in X:\", np.isnan(X).sum(), \"Inf in X:\", np.isinf(X).sum())\n",
    "print(\"NaN in Crisp y:\", np.isnan(crisp_y).sum(), \"Inf in Crisp y:\", np.isinf(crisp_y).sum())\n",
    "print(\"NaN in Fuzzy y:\", np.isnan(fuzzy_y).sum(), \"Inf in Fuzzy y:\", np.isinf(fuzzy_y).sum())\n",
    "\n",
    "# Neural Network parameters\n",
    "input_neurons = X.shape[1]  # Number of input features\n",
    "hidden_neurons = 10  # Number of neurons in hidden layer\n",
    "output_neurons = 1  # Single output (win or lose)\n",
    "learning_rate = 0.01  # Learning rate\n",
    "epochs = 10000  # Number of training epochs\n",
    "\n",
    "# Initialize weights randomly for input-to-hidden and hidden-to-output layers\n",
    "weights_input_hidden = np.random.uniform(-0.5, 0.5, (input_neurons, hidden_neurons))\n",
    "weights_hidden_output = np.random.uniform(-0.5, 0.5, (hidden_neurons, output_neurons))\n",
    "\n",
    "# Sigmoid activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training process for Crisp or Fuzzy Logic\n",
    "def train(X, y, logic_type=\"Crisp\"):\n",
    "    global weights_input_hidden, weights_hidden_output\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward Pass\n",
    "        hidden_layer_input = np.dot(X, weights_input_hidden)\n",
    "        hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "        \n",
    "        final_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "        predicted_output = sigmoid(final_layer_input)\n",
    "        \n",
    "        # Backward Pass\n",
    "        error = y - predicted_output\n",
    "        d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "        \n",
    "        error_hidden_layer = d_predicted_output.dot(weights_hidden_output.T)\n",
    "        d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "        \n",
    "        # Update weights\n",
    "        weights_hidden_output += hidden_layer_output.T.dot(d_predicted_output) * learning_rate\n",
    "        weights_input_hidden += X.T.dot(d_hidden_layer) * learning_rate\n",
    "        \n",
    "        # Print error every 1000 epochs\n",
    "        if epoch % 1000 == 0:\n",
    "            total_error = np.mean(np.abs(error))\n",
    "            print(f\"Epoch {epoch} ({logic_type} Logic) Error: {total_error}\")\n",
    "\n",
    "# Call the training function for both Crisp and Fuzzy logic\n",
    "print(\"\\nTraining for Crisp Logic:\")\n",
    "train(X, crisp_y, logic_type=\"Crisp\")\n",
    "\n",
    "print(\"\\nTraining for Fuzzy Logic:\")\n",
    "train(X, fuzzy_y, logic_type=\"Fuzzy\")\n",
    "\n",
    "# Predict function for Crisp or Fuzzy Logic\n",
    "def predict(X, logic_type=\"Crisp\"):\n",
    "    hidden_layer_input = np.dot(X, weights_input_hidden)\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "    \n",
    "    final_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "    predicted_output = sigmoid(final_layer_input)\n",
    "    \n",
    "    # For crisp, we round the prediction to 0 or 1 (binary classification)\n",
    "    if logic_type == \"Crisp\":\n",
    "        return np.where(predicted_output > 0.5, 1, 0)\n",
    "    # For fuzzy, we keep the continuous value\n",
    "    else:\n",
    "        return predicted_output\n",
    "\n",
    "# Predict and calculate accuracy for Crisp Logic\n",
    "crisp_predictions = predict(X, logic_type=\"Crisp\")\n",
    "crisp_accuracy = np.mean(crisp_predictions == crisp_y) * 100\n",
    "print(f\"\\nCrisp Logic Accuracy: {crisp_accuracy}%\")\n",
    "\n",
    "# Predict and calculate accuracy for Fuzzy Logic\n",
    "fuzzy_predictions = predict(X, logic_type=\"Fuzzy\")\n",
    "fuzzy_accuracy = np.mean(np.abs(fuzzy_predictions - fuzzy_y) < 0.1) * 100  # within 0.1 threshold\n",
    "print(f\"Fuzzy Logic Accuracy: {fuzzy_accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
